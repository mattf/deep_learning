{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"trainer.ipynb","provenance":[],"collapsed_sections":["lufMylhUc0WL"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vjkezi-2aAo6","executionInfo":{"status":"ok","timestamp":1613007625939,"user_tz":-330,"elapsed":1010,"user":{"displayName":"Subhan De","photoUrl":"","userId":"08832275770808375489"}},"outputId":"dbb28e7c-70f2-4b8c-a816-2b99fefbd88b"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Thu Feb 11 01:40:25 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.39       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   33C    P8    11W /  70W |      0MiB / 15079MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8ecMqKHaaNfw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613007668646,"user_tz":-330,"elapsed":21127,"user":{"displayName":"Subhan De","photoUrl":"","userId":"08832275770808375489"}},"outputId":"4c319143-16c5-4fbe-cbe0-348050b24ea5"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"41bcy1AMNjQv"},"source":["# !unzip '/content/drive/MyDrive/upwork/fashion/test_images.zip' -d '/content/drive/MyDrive/upwork/fashion/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iGiP2mDlcjEX","executionInfo":{"status":"ok","timestamp":1613007674520,"user_tz":-330,"elapsed":2531,"user":{"displayName":"Subhan De","photoUrl":"","userId":"08832275770808375489"}},"outputId":"19c610bb-4124-42ee-faa1-bf35ed2eb819"},"source":["import subprocess\r\n","\r\n","CUDA_version = [s for s in subprocess.check_output([\"nvcc\", \"--version\"]).decode(\"UTF-8\").split(\", \") if s.startswith(\"release\")][0].split(\" \")[-1]\r\n","print(\"CUDA version:\", CUDA_version)\r\n","\r\n","if CUDA_version == \"10.0\":\r\n","    torch_version_suffix = \"+cu100\"\r\n","elif CUDA_version == \"10.1\":\r\n","    torch_version_suffix = \"+cu101\"\r\n","elif CUDA_version == \"10.2\":\r\n","    torch_version_suffix = \"\"\r\n","else:\r\n","    torch_version_suffix = \"+cu110\"\r\n","\r\n","# torch_version_suffix = '+cpu'   "],"execution_count":3,"outputs":[{"output_type":"stream","text":["CUDA version: 10.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y9ozbRHRcfJf","executionInfo":{"status":"ok","timestamp":1613007854444,"user_tz":-330,"elapsed":178108,"user":{"displayName":"Subhan De","photoUrl":"","userId":"08832275770808375489"}},"outputId":"510975fb-3a00-4a0a-d56d-a2d47c30824a"},"source":["!pip install torch==1.7.1{torch_version_suffix} torchvision==0.8.2{torch_version_suffix} -f https://download.pytorch.org/whl/torch_stable.html ftfy regex\r\n","!pip install tez\r\n","!pip install deepspeed\r\n","!pip install efficientnet_pytorch\r\n","!pip uninstall albumentations\r\n","!pip install albumentations\r\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting torch==1.7.1+cu101\n","\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.7.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (735.4MB)\n","\u001b[K     |████████████████████████████████| 735.4MB 26kB/s \n","\u001b[?25hCollecting torchvision==0.8.2+cu101\n","\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.8.2%2Bcu101-cp36-cp36m-linux_x86_64.whl (12.8MB)\n","\u001b[K     |████████████████████████████████| 12.8MB 70.2MB/s \n","\u001b[?25hCollecting ftfy\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/e2/3b51c53dffb1e52d9210ebc01f1fb9f2f6eba9b3201fa971fd3946643c71/ftfy-5.8.tar.gz (64kB)\n","\u001b[K     |████████████████████████████████| 71kB 5.2MB/s \n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (2019.12.20)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from torch==1.7.1+cu101) (0.8)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.7.1+cu101) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch==1.7.1+cu101) (3.7.4.3)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.8.2+cu101) (7.0.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy) (0.2.5)\n","Building wheels for collected packages: ftfy\n","  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ftfy: filename=ftfy-5.8-cp36-none-any.whl size=45613 sha256=9ea71d23696355e51dddedc4b5b6731282205e156b46c3bd42ab8ed02d5eccca\n","  Stored in directory: /root/.cache/pip/wheels/ba/c0/ef/f28c4da5ac84a4e06ac256ca9182fc34fa57fefffdbc68425b\n","Successfully built ftfy\n","Installing collected packages: torch, torchvision, ftfy\n","  Found existing installation: torch 1.7.0+cu101\n","    Uninstalling torch-1.7.0+cu101:\n","      Successfully uninstalled torch-1.7.0+cu101\n","  Found existing installation: torchvision 0.8.1+cu101\n","    Uninstalling torchvision-0.8.1+cu101:\n","      Successfully uninstalled torchvision-0.8.1+cu101\n","Successfully installed ftfy-5.8 torch-1.7.1+cu101 torchvision-0.8.2+cu101\n","Collecting tez\n","  Downloading https://files.pythonhosted.org/packages/56/37/9b99ae05da3fa2b05a4cbb0cf78c50dfdcf805b55f29029c3cb6c5a0fee1/tez-0.1.2-py3-none-any.whl\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tez) (1.7.1+cu101)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->tez) (0.8)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->tez) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->tez) (3.7.4.3)\n","Installing collected packages: tez\n","Successfully installed tez-0.1.2\n","Collecting deepspeed\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/bd/b2b544ca1286252e9a559b1508e64d0d61af7a73b6bf6737568858128e11/deepspeed-0.3.10.tar.gz (281kB)\n","\u001b[K     |████████████████████████████████| 286kB 15.6MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.2 in /usr/local/lib/python3.6/dist-packages (from deepspeed) (1.7.1+cu101)\n","Requirement already satisfied: torchvision>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from deepspeed) (0.8.2+cu101)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from deepspeed) (4.41.1)\n","Collecting tensorboardX==1.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/12/dcaf67e1312475b26db9e45e7bb6f32b540671a9ee120b3a72d9e09bc517/tensorboardX-1.8-py2.py3-none-any.whl (216kB)\n","\u001b[K     |████████████████████████████████| 225kB 54.8MB/s \n","\u001b[?25hCollecting ninja\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/de/393468f2a37fc2c1dc3a06afc37775e27fde2d16845424141d4da62c686d/ninja-1.10.0.post2-py3-none-manylinux1_x86_64.whl (107kB)\n","\u001b[K     |████████████████████████████████| 112kB 55.3MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from deepspeed) (1.19.5)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from torch>=1.2->deepspeed) (0.8)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.2->deepspeed) (3.7.4.3)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.4.0->deepspeed) (7.0.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX==1.8->deepspeed) (1.15.0)\n","Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX==1.8->deepspeed) (3.12.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorboardX==1.8->deepspeed) (53.0.0)\n","Building wheels for collected packages: deepspeed\n","  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for deepspeed: filename=deepspeed-0.3.10-cp36-none-any.whl size=272624 sha256=35bb21a1d92502d5bdf3622d2c20eec857647fa38dcce27c48ae1e76d3ca64f3\n","  Stored in directory: /root/.cache/pip/wheels/a3/3c/9c/39a16330874a2c55f61fe2c501e120258975d509177ffdcda7\n","Successfully built deepspeed\n","Installing collected packages: tensorboardX, ninja, deepspeed\n","Successfully installed deepspeed-0.3.10 ninja-1.10.0.post2 tensorboardX-1.8\n","Collecting efficientnet_pytorch\n","  Downloading https://files.pythonhosted.org/packages/4e/83/f9c5f44060f996279e474185ebcbd8dbd91179593bffb9abe3afa55d085b/efficientnet_pytorch-0.7.0.tar.gz\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from efficientnet_pytorch) (1.7.1+cu101)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (3.7.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (1.19.5)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (0.8)\n","Building wheels for collected packages: efficientnet-pytorch\n","  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.0-cp36-none-any.whl size=16032 sha256=b55d636aea315acc27d2e97cbc380a55a7cc3985ffbcaeeb4b87a46cde619d99\n","  Stored in directory: /root/.cache/pip/wheels/e9/c6/e1/7a808b26406239712cfce4b5ceeb67d9513ae32aa4b31445c6\n","Successfully built efficientnet-pytorch\n","Installing collected packages: efficientnet-pytorch\n","Successfully installed efficientnet-pytorch-0.7.0\n","Uninstalling albumentations-0.1.12:\n","  Would remove:\n","    /usr/local/lib/python3.6/dist-packages/albumentations-0.1.12.dist-info/*\n","    /usr/local/lib/python3.6/dist-packages/albumentations/*\n","Proceed (y/n)? y\n","  Successfully uninstalled albumentations-0.1.12\n","Collecting albumentations\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/58/63fb1d742dc42d9ba2800ea741de1f2bc6bb05548d8724aa84794042eaf2/albumentations-0.5.2-py3-none-any.whl (72kB)\n","\u001b[K     |████████████████████████████████| 81kB 8.4MB/s \n","\u001b[?25hRequirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.6/dist-packages (from albumentations) (0.16.2)\n","Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from albumentations) (1.19.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from albumentations) (1.4.1)\n","Collecting imgaug>=0.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/b1/af3142c4a85cba6da9f4ebb5ff4e21e2616309552caca5e8acefe9840622/imgaug-0.4.0-py2.py3-none-any.whl (948kB)\n","\u001b[K     |████████████████████████████████| 952kB 22.6MB/s \n","\u001b[?25hCollecting opencv-python-headless>=4.1.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/fc/4da675cc522a749ebbcf85c5a63fba844b2d44c87e6f24e3fdb147df3270/opencv_python_headless-4.5.1.48-cp36-cp36m-manylinux2014_x86_64.whl (37.6MB)\n","\u001b[K     |████████████████████████████████| 37.6MB 85kB/s \n","\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from albumentations) (3.13)\n","Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16.1->albumentations) (7.0.0)\n","Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16.1->albumentations) (3.2.2)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16.1->albumentations) (2.5)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16.1->albumentations) (2.4.1)\n","Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16.1->albumentations) (1.1.1)\n","Requirement already satisfied: Shapely in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations) (1.7.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations) (1.15.0)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations) (4.1.2.30)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.4.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.3.1)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.8.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (0.10.0)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.16.1->albumentations) (4.4.2)\n","Installing collected packages: imgaug, opencv-python-headless, albumentations\n","  Found existing installation: imgaug 0.2.9\n","    Uninstalling imgaug-0.2.9:\n","      Successfully uninstalled imgaug-0.2.9\n","Successfully installed albumentations-0.5.2 imgaug-0.4.0 opencv-python-headless-4.5.1.48\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pxNwUClOlo8Y"},"source":["# !rm -rf '/content/drive/MyDrive/upwork/fashion/efficientnet_vectors'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yrcP92mGcru5","executionInfo":{"status":"ok","timestamp":1613008536376,"user_tz":-330,"elapsed":1337,"user":{"displayName":"Subhan De","photoUrl":"","userId":"08832275770808375489"}},"outputId":"6d30afb3-9def-4a5c-dfd6-2f5e6cedf96c"},"source":["# root = '/content/drive/MyDrive/upwork/img'\r\n","# root =   \"/content/drive/My Drive/Colab Notebooks/shared_session/img/\"\r\n","# root = '/content/drive/MyDrive/upwork/fashion'\r\n","root = '/content/drive/MyDrive/fashion'\r\n","\r\n","\r\n","import os, sys\r\n","print( os.getcwd())\r\n","os.chdir(root)\r\n","print( os.getcwd())\r\n"],"execution_count":11,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/fashion\n","/content/drive/MyDrive/fashion\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"w9INwxejLbQK","executionInfo":{"status":"ok","timestamp":1613008533441,"user_tz":-330,"elapsed":1018,"user":{"displayName":"Subhan De","photoUrl":"","userId":"08832275770808375489"}}},"source":["# import pandas as pd\n","# ids = [[i.split('.')[0]] for i in os.listdir('./images')]\n","# df = pd.DataFrame(ids, columns=['id'])\n","# df.to_csv('images.csv', index=False)\n","# df.shape"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8oXlwF4Qezha","executionInfo":{"status":"ok","timestamp":1613008949998,"user_tz":-330,"elapsed":1837,"user":{"displayName":"Subhan De","photoUrl":"","userId":"08832275770808375489"}},"outputId":"8d41c1cd-8003-4932-fb49-712b23ca07a9"},"source":["print(len(os.listdir('./images')))\n","# print(len(os.listdir('./efficientnet_vectors')))\n","print(len(os.listdir('./big_model_vectors')))\n","# print(len(os.listdir('./final_vectors')))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["44441\n","44441\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rvy587eVS3yN","executionInfo":{"status":"ok","timestamp":1612970476008,"user_tz":-330,"elapsed":1055,"user":{"displayName":"Subhan De","photoUrl":"","userId":"08832275770808375489"}},"outputId":"9ca500d5-f10e-47bf-a2cb-3ada60eb90fd"},"source":["print(len(os.listdir('./test_images')))\n","# print(len(os.listdir('./test_efficientnet_vectors')))\n","print(len(os.listdir('./test_big_model_vectors')))\n","print(len(os.listdir('./test_final_vectors')))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["4633\n","4633\n","4633\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"h1nqWT-Bhw_a"},"source":["# !rm -rf '/content/drive/MyDrive/upwork/fashion/efficientnet_vectors'\n","# !rm -rf '/content/drive/MyDrive/upwork/fashion/big_model_vectors'\n","# !rm -rf '/content/drive/MyDrive/upwork/fashion/final_vectors'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LjYciIcacxtd"},"source":["## Stage 1 : DF Preprocess"]},{"cell_type":"code","metadata":{"id":"_6_p2ADfdKCt"},"source":["# !python model_transfer_v3.py --stage='df_preprocess' --base_path='./' --image_path='./images' \\\r\n","#                             --base_df='styles.csv' --root_df='df_final.csv' --train_df='train.csv' --val_df='val.csv'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kVGara5OcyWL","executionInfo":{"status":"ok","timestamp":1611982146352,"user_tz":-330,"elapsed":8954,"user":{"displayName":"Subhan De","photoUrl":"","userId":"08832275770808375489"}},"outputId":"ba64ba72-bff7-4918-9ca7-3d8d55257a65"},"source":["!python model_transfer_v3.py --stage='df_preprocess' --base_path='./' --image_path='./images' \\\r\n","                            --base_df='styles.csv' --root_df='df_final.csv' --train_df='train.csv' --val_df='val.csv'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["df_preprocess\n","Total Number of Images:  44441\n","b'Skipping line 6044: expected 10 fields, saw 11\\nSkipping line 6569: expected 10 fields, saw 11\\nSkipping line 7399: expected 10 fields, saw 11\\nSkipping line 7939: expected 10 fields, saw 11\\nSkipping line 9026: expected 10 fields, saw 11\\nSkipping line 10264: expected 10 fields, saw 11\\nSkipping line 10427: expected 10 fields, saw 11\\nSkipping line 10905: expected 10 fields, saw 11\\nSkipping line 11373: expected 10 fields, saw 11\\nSkipping line 11945: expected 10 fields, saw 11\\nSkipping line 14112: expected 10 fields, saw 11\\nSkipping line 14532: expected 10 fields, saw 11\\nSkipping line 15076: expected 10 fields, saw 12\\nSkipping line 29906: expected 10 fields, saw 11\\nSkipping line 31625: expected 10 fields, saw 11\\nSkipping line 33020: expected 10 fields, saw 11\\nSkipping line 35748: expected 10 fields, saw 11\\nSkipping line 35962: expected 10 fields, saw 11\\nSkipping line 37770: expected 10 fields, saw 11\\nSkipping line 38105: expected 10 fields, saw 11\\nSkipping line 38275: expected 10 fields, saw 11\\nSkipping line 38404: expected 10 fields, saw 12\\n'\n","Dataset Size:  (44424, 10)\n","Total 5 images didn't found\n","Final Dataset Size:  (43905, 8)\n","Stage: df_preprocess Finished ------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EVyeMXeDgU_M"},"source":["# !cp -r './dataset/images/' '/content/images/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dxGTitXvgmR1"},"source":["# os.chdir('/content')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h8TsiqTA-q5n"},"source":["# import time\r\n","# while(True):\r\n","#   time.sleep(30)\r\n","#   pass"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lufMylhUc0WL"},"source":["## Stage 2 : Extract Efficient"]},{"cell_type":"code","metadata":{"id":"RcImV0YQiV8E"},"source":["# !python model_transfer_v3.py --stage='extract_efficienet' --base_path='./' --image_path='./images' \\\r\n","#                             --output_vector_path='./efficientnet_vectors' \\\r\n","#                             --root_df='df_final.csv' --test_df='df_final.csv' --batch_size=16\r\n","\r\n","!nohup python3 model_transfer_v3.py --stage='extract_efficienet' --base_path='./' --image_path='./images' \\\r\n","                            --output_vector_path='./efficientnet_vectors' \\\r\n","                            --root_df='df_final.csv' --test_df='images.csv' --batch_size=16 &> nohup2.out & "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WpT7sRQM-oQQ"},"source":["## Stage 2 : Extract Big Model1\r\n"]},{"cell_type":"code","metadata":{"id":"4suAekKz-oyZ"},"source":["# !python model_transfer_v3.py --stage='extract_bigmodel1' --base_path='./' --image_path='./data/fashion-dataset/images' \\\r\n","#                             --output_vector_path='./fashion-dataset/big_model1_vectors' --model_name='model' \\\r\n","#                             --root_df='df_final.csv' --test_df='df_final.csv' --batch_size=32\r\n","\r\n","!nohup python3 model_transfer_v3.py --stage='extract_bigmodel1' --base_path='./' --image_path='./images' \\\r\n","                            --output_vector_path='./big_model_vectors' --model_name='model' \\\r\n","                            --root_df='df_final.csv' --test_df='images.csv' --batch_size=16 &> nohup2.out &\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9zQ-M4QEWP9R"},"source":["## Stage 3 : train from big model1 vectors"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DuchNY0TWTGf","executionInfo":{"status":"ok","timestamp":1611997363398,"user_tz":-330,"elapsed":1131,"user":{"displayName":"Subhan De","photoUrl":"","userId":"08832275770808375489"}},"outputId":"440daf91-766b-4351-d1f2-7ced0abe3c02"},"source":["# !python model_transfer_v3.py --stage='train_small' --base_path='./' --image_path='./images' \\\r\n","#         --intermediate_vector_path='./big_model_vectors' --model_name='fashion_big_model' \\\r\n","#         --input_vector_size=512 --intermediate_vector_size=128 --root_df='df_final.csv' \\\r\n","#         --train_df='train.csv' --val_df='val.csv' --batch_size=32 --epochs=30 --save_interval=5\r\n","\r\n","\r\n","!nohup python3 model_transfer_v3.py --stage='train_small' --base_path='./' --image_path='./images' \\\r\n","        --intermediate_vector_path='./big_model_vectors' --model_name='fashion_big_model' \\\r\n","        --input_vector_size=512 --intermediate_vector_size=128 --root_df='df_final.csv' --train_df='train.csv' \\\r\n","        --val_df='val.csv' --batch_size=32 --epochs=20 --save_interval=5 &\r\n","        "],"execution_count":null,"outputs":[{"output_type":"stream","text":["nohup: appending output to 'nohup.out'\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4B8E9iWsptLK"},"source":["## Stage 4 : train from efficient vectors"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GvIdqRNvpwBS","executionInfo":{"status":"ok","timestamp":1611999578966,"user_tz":-330,"elapsed":1168,"user":{"displayName":"Subhan De","photoUrl":"","userId":"08832275770808375489"}},"outputId":"05258b77-358d-4523-c094-c37437caf2f6"},"source":["# !python model_transfer_v3.py --stage='train_small' --base_path='./' --image_path='./images' \\\r\n","#           --intermediate_vector_path='./efficientnet_vectors' --model_name='fashion_efficient' \\\r\n","#           --input_vector_size=1536 --intermediate_vector_size=512 --root_df='df_final.csv' \\\r\n","#           --train_df='train.csv' --val_df='val.csv' --batch_size=32 --epochs=30 --save_interval=5\r\n","\r\n","\r\n","!nohup python3 model_transfer_v3.py --stage='train_small' --base_path='./' --image_path='./images' \\\r\n","          --intermediate_vector_path='./efficientnet_vectors' --model_name='fashion_efficient' \\\r\n","          --input_vector_size=1536 --intermediate_vector_size=512 --root_df='df_final.csv' \\\r\n","          --train_df='train.csv' --val_df='val.csv' --batch_size=32 --epochs=30 --save_interval=5 &"],"execution_count":null,"outputs":[{"output_type":"stream","text":["nohup: appending output to 'nohup.out'\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"64aDGa3j3TEn"},"source":["## Stage 5 : extract final vectors"]},{"cell_type":"code","metadata":{"id":"Skgkgvfs3NHe"},"source":["# !python model_transfer_v3.py --stage='extract_small' --base_path='./' --image_path='./images' \\\r\n","#       --intermediate_vector_path='./big_model_vectors'  --output_vector_path='./final_vectors' \\\r\n","#       --model_name='fashion_big_model_best' --input_vector_size=512 --intermediate_vector_size=128 --root_df='df_final.csv' --test_df='df_final.csv'\r\n","\r\n","!nohup python3 model_transfer_v3.py --stage='extract_small' --base_path='./' --image_path='./images' \\\r\n","      --intermediate_vector_path='./big_model_vectors'  --output_vector_path='./final_vectors' \\\r\n","      --model_name='fashion_big_model_best' --input_vector_size=512 --intermediate_vector_size=128 \\\r\n","      --root_df='df_final.csv' --test_df='images.csv' --batch_size=32 &> nohup2.out &"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JRGaETJ98NkU","executionInfo":{"status":"ok","timestamp":1612004271689,"user_tz":-330,"elapsed":1554,"user":{"displayName":"Subhan De","photoUrl":"","userId":"08832275770808375489"}},"outputId":"bca5f80d-47ee-4657-edbc-e533163a586f"},"source":["len(os.listdir('/content/drive/MyDrive/upwork/fashion/final_vectors'))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["43905"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"eb68l2Qz7X0d"},"source":["## Stage 6 : train from logistic regression"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A6pLes1_7a-7","executionInfo":{"status":"ok","timestamp":1612004409465,"user_tz":-330,"elapsed":1479,"user":{"displayName":"Subhan De","photoUrl":"","userId":"08832275770808375489"}},"outputId":"d3621ee5-ec8b-48e4-9035-a4ac67292dcd"},"source":["# !python model_transfer_v3.py --stage='check_vectors' --base_path='./' --image_path='./images' \\\r\n","#         --intermediate_vector_path='./final_vectors' --model_name='logistic' \\\r\n","#         --logistic_reg_targ_col='gender' --root_df='df_final.csv' --train_df='train.csv' --val_df='val.csv' \r\n","\r\n","!nohup python3 model_transfer_v3.py --stage='check_vectors' --base_path='./' --image_path='./images' \\\r\n","        --intermediate_vector_path='./final_vectors' --model_name='logistic' \\\r\n","        --logistic_reg_targ_col='gender' --root_df='df_final.csv' --train_df='train.csv' --val_df='val.csv' &"],"execution_count":null,"outputs":[{"output_type":"stream","text":["nohup: appending output to 'nohup.out'\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jz7hdFRqMIfO"},"source":["\r\n","\r\n","## Stage 7: Training with Deepspeed "]},{"cell_type":"code","metadata":{"id":"F_rzGPK2MFN4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613013473868,"user_tz":-330,"elapsed":264102,"user":{"displayName":"Subhan De","photoUrl":"","userId":"08832275770808375489"}},"outputId":"df4dfd60-8c77-4362-853b-554acfe11c99"},"source":["!deepspeed trainer_deepspeed.py --deepspeed_config ds_config.json"],"execution_count":35,"outputs":[{"output_type":"stream","text":["[2021-02-11 03:13:31,642] [WARNING] [runner.py:117:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n","[2021-02-11 03:13:31,677] [INFO] [runner.py:355:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 trainer_deepspeed.py --deepspeed_config ds_config.json\n","[2021-02-11 03:13:32,535] [INFO] [launch.py:71:main] 0 NCCL_VERSION 2.8.3\n","[2021-02-11 03:13:32,535] [INFO] [launch.py:78:main] WORLD INFO DICT: {'localhost': [0]}\n","[2021-02-11 03:13:32,536] [INFO] [launch.py:87:main] nnodes=1, num_local_procs=1, node_rank=0\n","[2021-02-11 03:13:32,536] [INFO] [launch.py:99:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n","[2021-02-11 03:13:32,536] [INFO] [launch.py:100:main] dist_world_size=1\n","[2021-02-11 03:13:32,536] [INFO] [launch.py:103:main] Setting CUDA_VISIBLE_DEVICES=0\n","{'base_dir': './', 'root_df': 'df_final.csv', 'train_df': 'train.csv', 'val_df': 'val.csv', 'data_path': './big_model_vectors', 'batch_size': 32, 'epochs': 5, 'in_features': 512, 'intemediate_features': 128, 'patience': 5, 'save_interval': 5, 'model_name': 'fashion', 'device': 'cuda', 'use_deepspeed': True}\n","============================================\n","Training model with deepspeed\n","============================================\n","[2021-02-11 03:13:34,395] [INFO] [logging.py:60:log_dist] [Rank -1] DeepSpeed info: version=0.3.10, git-hash=unknown, git-branch=unknown\n","[2021-02-11 03:13:34,395] [INFO] [distributed.py:40:init_distributed] Initializing torch distributed with backend: nccl\n","[2021-02-11 03:13:38,753] [INFO] [engine.py:72:_initialize_parameter_parallel_groups] data_parallel_size: 1, parameter_parallel_size: 1\n","Using /root/.cache/torch_extensions as PyTorch extensions root...\n","Detected CUDA files, patching ldflags\n","Emitting ninja build file /root/.cache/torch_extensions/fused_adam/build.ninja...\n","Building extension module fused_adam...\n","Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n","[1/3] /usr/local/cuda/bin/nvcc -DTORCH_EXTENSION_NAME=fused_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/usr/local/lib/python3.6/dist-packages/deepspeed/ops/csrc/includes -isystem /usr/local/lib/python3.6/dist-packages/torch/include -isystem /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.6/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.6/dist-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.6m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_75,code=sm_75 --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_75,code=compute_75 -std=c++14 -c /usr/local/lib/python3.6/dist-packages/deepspeed/ops/csrc/adam/multi_tensor_adam.cu -o multi_tensor_adam.cuda.o \n","[2/3] c++ -MMD -MF fused_adam_frontend.o.d -DTORCH_EXTENSION_NAME=fused_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/usr/local/lib/python3.6/dist-packages/deepspeed/ops/csrc/includes -isystem /usr/local/lib/python3.6/dist-packages/torch/include -isystem /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.6/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.6/dist-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.6m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -c /usr/local/lib/python3.6/dist-packages/deepspeed/ops/csrc/adam/fused_adam_frontend.cpp -o fused_adam_frontend.o \n","[3/3] c++ fused_adam_frontend.o multi_tensor_adam.cuda.o -shared -L/usr/local/lib/python3.6/dist-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o fused_adam.so\n","Loading extension module fused_adam...\n","Time to load fused_adam op: 22.650890588760376 seconds\n","[2021-02-11 03:14:02,328] [INFO] [engine.py:518:_configure_optimizer] Using DeepSpeed Optimizer param name adam as basic optimizer\n","[2021-02-11 03:14:02,329] [INFO] [engine.py:521:_configure_optimizer] DeepSpeed Basic Optimizer = FusedAdam (\n","Parameter Group 0\n","    betas: [0.8, 0.999]\n","    bias_correction: True\n","    eps: 1e-08\n","    lr: 0.001\n","    weight_decay: 3e-07\n",")\n","[2021-02-11 03:14:02,329] [INFO] [engine.py:551:_configure_optimizer] DeepSpeed Final Optimizer = FusedAdam (\n","Parameter Group 0\n","    betas: [0.8, 0.999]\n","    bias_correction: True\n","    eps: 1e-08\n","    lr: 0.001\n","    weight_decay: 3e-07\n",")\n","[2021-02-11 03:14:02,329] [INFO] [engine.py:382:_configure_lr_scheduler] DeepSpeed using configured LR scheduler = WarmupLR\n","[2021-02-11 03:14:02,329] [INFO] [logging.py:60:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7fa3135f5208>\n","[2021-02-11 03:14:02,329] [INFO] [logging.py:60:log_dist] [Rank 0] step=0, skipped=0, lr=[0.001], mom=[[0.8, 0.999]]\n","[2021-02-11 03:14:02,330] [INFO] [config.py:705:print] DeepSpeedEngine configuration:\n","[2021-02-11 03:14:02,330] [INFO] [config.py:709:print]   activation_checkpointing_config  <deepspeed.runtime.activation_checkpointing.config.DeepSpeedActivationCheckpointingConfig object at 0x7fa31368bcf8>\n","[2021-02-11 03:14:02,330] [INFO] [config.py:709:print]   allreduce_always_fp32 ........ False\n","[2021-02-11 03:14:02,330] [INFO] [config.py:709:print]   amp_enabled .................. False\n","[2021-02-11 03:14:02,330] [INFO] [config.py:709:print]   amp_params ................... False\n","[2021-02-11 03:14:02,330] [INFO] [config.py:709:print]   disable_allgather ............ False\n","[2021-02-11 03:14:02,330] [INFO] [config.py:709:print]   dump_state ................... False\n","[2021-02-11 03:14:02,330] [INFO] [config.py:709:print]   dynamic_loss_scale_args ...... None\n","[2021-02-11 03:14:02,330] [INFO] [config.py:709:print]   elasticity_enabled ........... False\n","[2021-02-11 03:14:02,330] [INFO] [config.py:709:print]   fp16_enabled ................. False\n","[2021-02-11 03:14:02,330] [INFO] [config.py:709:print]   global_rank .................. 0\n","[2021-02-11 03:14:02,330] [INFO] [config.py:709:print]   gradient_accumulation_steps .. 1\n","[2021-02-11 03:14:02,330] [INFO] [config.py:709:print]   gradient_clipping ............ 0.0\n","[2021-02-11 03:14:02,330] [INFO] [config.py:709:print]   gradient_predivide_factor .... 1.0\n","[2021-02-11 03:14:02,330] [INFO] [config.py:709:print]   initial_dynamic_scale ........ 4294967296\n","[2021-02-11 03:14:02,331] [INFO] [config.py:709:print]   loss_scale ................... 0\n","[2021-02-11 03:14:02,331] [INFO] [config.py:709:print]   memory_breakdown ............. False\n","[2021-02-11 03:14:02,331] [INFO] [config.py:709:print]   optimizer_legacy_fusion ...... False\n","[2021-02-11 03:14:02,331] [INFO] [config.py:709:print]   optimizer_name ............... adam\n","[2021-02-11 03:14:02,331] [INFO] [config.py:709:print]   optimizer_params ............. {'lr': 0.001, 'betas': [0.8, 0.999], 'eps': 1e-08, 'weight_decay': 3e-07, 'adam_w_mode': True}\n","[2021-02-11 03:14:02,331] [INFO] [config.py:709:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n","[2021-02-11 03:14:02,331] [INFO] [config.py:709:print]   pld_enabled .................. False\n","[2021-02-11 03:14:02,331] [INFO] [config.py:709:print]   pld_params ................... False\n","[2021-02-11 03:14:02,331] [INFO] [config.py:709:print]   prescale_gradients ........... False\n","[2021-02-11 03:14:02,331] [INFO] [config.py:709:print]   scheduler_name ............... WarmupLR\n","[2021-02-11 03:14:02,331] [INFO] [config.py:709:print]   scheduler_params ............. {'warmup_min_lr': 0, 'warmup_max_lr': 0.001, 'warmup_num_steps': 1000}\n","[2021-02-11 03:14:02,331] [INFO] [config.py:709:print]   sparse_attention ............. None\n","[2021-02-11 03:14:02,331] [INFO] [config.py:709:print]   sparse_gradients_enabled ..... False\n","[2021-02-11 03:14:02,331] [INFO] [config.py:709:print]   steps_per_print .............. 2000\n","[2021-02-11 03:14:02,331] [INFO] [config.py:709:print]   tensorboard_enabled .......... False\n","[2021-02-11 03:14:02,331] [INFO] [config.py:709:print]   tensorboard_job_name ......... DeepSpeedJobName\n","[2021-02-11 03:14:02,331] [INFO] [config.py:709:print]   tensorboard_output_path ...... \n","[2021-02-11 03:14:02,332] [INFO] [config.py:709:print]   train_batch_size ............. 4\n","[2021-02-11 03:14:02,332] [INFO] [config.py:709:print]   train_micro_batch_size_per_gpu  4\n","[2021-02-11 03:14:02,332] [INFO] [config.py:709:print]   wall_clock_breakdown ......... False\n","[2021-02-11 03:14:02,332] [INFO] [config.py:709:print]   world_size ................... 1\n","[2021-02-11 03:14:02,332] [INFO] [config.py:709:print]   zero_allow_untested_optimizer  False\n","[2021-02-11 03:14:02,332] [INFO] [config.py:709:print]   zero_config .................. {\n","    \"allgather_bucket_size\": 500000000,\n","    \"allgather_partitions\": true,\n","    \"contiguous_gradients\": false,\n","    \"cpu_offload\": false,\n","    \"elastic_checkpoint\": true,\n","    \"load_from_fp32_weights\": true,\n","    \"overlap_comm\": false,\n","    \"reduce_bucket_size\": 500000000,\n","    \"reduce_scatter\": true,\n","    \"stage\": 0\n","}\n","[2021-02-11 03:14:02,332] [INFO] [config.py:709:print]   zero_enabled ................. False\n","[2021-02-11 03:14:02,332] [INFO] [config.py:709:print]   zero_optimization_stage ...... 0\n","[2021-02-11 03:14:02,332] [INFO] [config.py:716:print]   json = {\n","    \"custom_params\":{\n","        \"base_dir\":\"./\",\n","        \"batch_size\":32,\n","        \"data_path\":\"./big_model_vectors\",\n","        \"device\":\"cuda\",\n","        \"epochs\":5,\n","        \"in_features\":512,\n","        \"intemediate_features\":128,\n","        \"model_name\":\"fashion\",\n","        \"patience\":5,\n","        \"root_df\":\"df_final.csv\",\n","        \"save_interval\":5,\n","        \"train_df\":\"train.csv\",\n","        \"val_df\":\"val.csv\"\n","    },\n","    \"optimizer\":{\n","        \"params\":{\n","            \"adam_w_mode\":true,\n","            \"betas\":[\n","                0.8,\n","                0.999\n","            ],\n","            \"eps\":1e-08,\n","            \"lr\":0.001,\n","            \"weight_decay\":3e-07\n","        },\n","        \"type\":\"Adam\"\n","    },\n","    \"scheduler\":{\n","        \"params\":{\n","            \"warmup_max_lr\":0.001,\n","            \"warmup_min_lr\":0,\n","            \"warmup_num_steps\":1000\n","        },\n","        \"type\":\"WarmupLR\"\n","    },\n","    \"steps_per_print\":2000,\n","    \"train_batch_size\":4,\n","    \"wall_clock_breakdown\":false\n","}\n","Using /root/.cache/torch_extensions as PyTorch extensions root...\n","Creating extension directory /root/.cache/torch_extensions/utils...\n","Emitting ninja build file /root/.cache/torch_extensions/utils/build.ninja...\n","Building extension module utils...\n","Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n","[1/2] c++ -MMD -MF flatten_unflatten.o.d -DTORCH_EXTENSION_NAME=utils -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /usr/local/lib/python3.6/dist-packages/torch/include -isystem /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.6/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.6/dist-packages/torch/include/THC -isystem /usr/include/python3.6m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -c /usr/local/lib/python3.6/dist-packages/deepspeed/ops/csrc/utils/flatten_unflatten.cpp -o flatten_unflatten.o \n","[2/2] c++ flatten_unflatten.o -shared -L/usr/local/lib/python3.6/dist-packages/torch/lib -lc10 -ltorch_cpu -ltorch -ltorch_python -o utils.so\n","Loading extension module utils...\n","Time to load utils op: 11.972181558609009 seconds\n","100% 1098/1098 [00:37<00:00, 29.51it/s, accuracy=0.735, loss=6.49, stage=train]\n","100% 275/275 [00:08<00:00, 32.39it/s, accuracy=0.839, loss=3.37, stage=valid]\n","Model Saved | Loss impoved from inf -----> 3.372639032710682\n"," 82% 901/1098 [00:29<00:05, 33.31it/s, accuracy=0.809, loss=4.12, stage=train][2021-02-11 03:15:29,032] [INFO] [logging.py:60:log_dist] [Rank 0] step=2000, skipped=0, lr=[0.001], mom=[[0.8, 0.999]]\n","100% 1098/1098 [00:35<00:00, 31.31it/s, accuracy=0.81, loss=4.1, stage=train]\n","100% 275/275 [00:08<00:00, 33.63it/s, accuracy=0.85, loss=3.06, stage=valid]\n","Model Saved | Loss impoved from 3.372639032710682 -----> 3.060875938588923\n","100% 1098/1098 [00:34<00:00, 31.50it/s, accuracy=0.818, loss=3.85, stage=train]\n","100% 275/275 [00:08<00:00, 32.49it/s, accuracy=0.852, loss=2.99, stage=valid]\n","Model Saved | Loss impoved from 3.060875938588923 -----> 2.9851723220131614\n"," 64% 705/1098 [00:22<00:12, 31.79it/s, accuracy=0.822, loss=3.73, stage=train][2021-02-11 03:16:48,869] [INFO] [logging.py:60:log_dist] [Rank 0] step=4000, skipped=0, lr=[0.001], mom=[[0.8, 0.999]]\n","100% 1098/1098 [00:34<00:00, 31.52it/s, accuracy=0.823, loss=3.71, stage=train]\n","100% 275/275 [00:08<00:00, 32.77it/s, accuracy=0.854, loss=2.9, stage=valid]\n","Model Saved | Loss impoved from 2.9851723220131614 -----> 2.8994026990370316\n","100% 1098/1098 [00:34<00:00, 31.90it/s, accuracy=0.825, loss=3.65, stage=train]\n","100% 275/275 [00:08<00:00, 32.09it/s, accuracy=0.857, loss=2.87, stage=valid]\n","Model Saved | Loss impoved from 2.8994026990370316 -----> 2.869103607264432\n","Model Saved\n","Finished Training\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lfEtLu7FiKLB"},"source":["## Stage 8: Training with PyTorch"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1HSeyJpBiUkm","executionInfo":{"status":"ok","timestamp":1613013171921,"user_tz":-330,"elapsed":228436,"user":{"displayName":"Subhan De","photoUrl":"","userId":"08832275770808375489"}},"outputId":"c0bc95ed-5c97-44d6-a074-5b289158a06b"},"source":["!python trainer_deepspeed.py --config=ds_config.json"],"execution_count":34,"outputs":[{"output_type":"stream","text":["{'base_dir': './', 'root_df': 'df_final.csv', 'train_df': 'train.csv', 'val_df': 'val.csv', 'data_path': './big_model_vectors', 'batch_size': 32, 'epochs': 5, 'in_features': 512, 'intemediate_features': 128, 'patience': 5, 'save_interval': 5, 'model_name': 'fashion', 'device': 'cuda', 'use_deepspeed': False}\n","============================================\n","Training model with pytorch\n","============================================\n","100% 1098/1098 [00:35<00:00, 31.06it/s, accuracy=0.691, loss=8.13, stage=train]\n","100% 275/275 [00:08<00:00, 33.14it/s, accuracy=0.827, loss=4.15, stage=valid]\n","Model Saved | Loss impoved from inf -----> 4.149080743789673\n","100% 1098/1098 [00:35<00:00, 31.31it/s, accuracy=0.797, loss=4.67, stage=train]\n","100% 275/275 [00:08<00:00, 33.26it/s, accuracy=0.842, loss=3.42, stage=valid]\n","Model Saved | Loss impoved from 4.149080743789673 -----> 3.4151849200508813\n","100% 1098/1098 [00:38<00:00, 28.82it/s, accuracy=0.81, loss=4.17, stage=train]\n","100% 275/275 [00:08<00:00, 32.02it/s, accuracy=0.847, loss=3.18, stage=valid]\n","Model Saved | Loss impoved from 3.4151849200508813 -----> 3.1789661736921833\n","100% 1098/1098 [00:34<00:00, 31.60it/s, accuracy=0.816, loss=3.97, stage=train]\n","100% 275/275 [00:08<00:00, 32.52it/s, accuracy=0.852, loss=3.05, stage=valid]\n","Model Saved | Loss impoved from 3.1789661736921833 -----> 3.053932237625122\n","100% 1098/1098 [00:35<00:00, 31.13it/s, accuracy=0.821, loss=3.83, stage=train]\n","100% 275/275 [00:08<00:00, 32.44it/s, accuracy=0.854, loss=3, stage=valid]\n","Model Saved | Loss impoved from 3.053932237625122 -----> 3.000276828245683\n","Model Saved\n","Finished Training\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4Z_XrdsARSgM"},"source":["# Inference"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oIPEh5euTlHk","executionInfo":{"status":"ok","timestamp":1612027335583,"user_tz":-330,"elapsed":1226,"user":{"displayName":"Subhan De","photoUrl":"","userId":"08832275770808375489"}},"outputId":"c7e89d34-3456-4fd1-ebdf-26a3010dd64c"},"source":["import pandas as pd\r\n","ids = [[i.split('.')[0]] for i in os.listdir('./test_images')]\r\n","df = pd.DataFrame(ids, columns=['id'])\r\n","df.to_csv('test.csv', index=False)\r\n","df.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4633, 1)"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"UYyKunnsU-x7"},"source":["len(os.listdir('/content/drive/MyDrive/upwork/fashion/test_big_model_vectors'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cQb8KhQbRX7k"},"source":["## Stage 6: Test :> Extract Big Model1"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YsdmYvE5RT21","executionInfo":{"status":"ok","timestamp":1612027695163,"user_tz":-330,"elapsed":1116,"user":{"displayName":"Subhan De","photoUrl":"","userId":"08832275770808375489"}},"outputId":"94ed3eb6-45d0-4b95-e8c7-da8a8b407a27"},"source":["!nohup python3 model_transfer_v3.py --stage='extract_bigmodel1' --base_path='./' --image_path='./test_images' \\\r\n","        --output_vector_path='./test_big_model_vectors' --model_name='model' --root_df='df_final.csv' --test_df='test.csv' --batch_size=32 &"],"execution_count":null,"outputs":[{"output_type":"stream","text":["nohup: appending output to 'nohup.out'\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9jneamRHRckw"},"source":["## Stage 7: Test :> extract final vectors"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FdKWX0y5ReuH","executionInfo":{"status":"ok","timestamp":1612027851556,"user_tz":-330,"elapsed":1268,"user":{"displayName":"Subhan De","photoUrl":"","userId":"08832275770808375489"}},"outputId":"83734848-2f53-4adf-de2e-270da3e83c93"},"source":["!nohup python3 model_transfer_v3.py --stage='extract_small' --base_path='./' --image_path='./test_images' \\\r\n","          --intermediate_vector_path='./test_big_model_vectors'  --output_vector_path='./test_final_vectors' \\\r\n","          --model_name='fashion_big_model_best' --input_vector_size=512 --intermediate_vector_size=128 \\\r\n","          --root_df='df_final.csv' --test_df='test.csv' --batch_size=32 &"],"execution_count":null,"outputs":[{"output_type":"stream","text":["nohup: appending output to 'nohup.out'\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"y_ukHAduRjSA"},"source":["## Stage 8 : Test :> prediction\r\n","\r\n","**This will generate pred_df.csv and if label are present in input df then it will also calculate accuracy**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X7SUDGbtRmIs","executionInfo":{"status":"ok","timestamp":1612028027559,"user_tz":-330,"elapsed":1454,"user":{"displayName":"Subhan De","photoUrl":"","userId":"08832275770808375489"}},"outputId":"109886ec-980d-48b6-ed9f-d7cc6870e3c4"},"source":["# Prdiction on labeled data\r\n","!nohup python3 model_transfer_v3.py --stage='predict_small' --base_path='./' --image_path='./images' \\\r\n","        --intermediate_vector_path='./big_model_vectors' --model_name='fashion_big_model_best' --input_vector_size=512 \\\r\n","        --intermediate_vector_size=128 --root_df='df_final.csv' --test_df='df_final_with_original_class.csv' \\\r\n","        --base_df='df_final_with_original_class.csv' --pred_df='df_final_pred.csv' --batch_size=32 &"],"execution_count":null,"outputs":[{"output_type":"stream","text":["nohup: appending output to 'nohup.out'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4x1jGA1KRsiM","executionInfo":{"status":"ok","timestamp":1612933340895,"user_tz":-330,"elapsed":900,"user":{"displayName":"Subhan De","photoUrl":"","userId":"08832275770808375489"}},"outputId":"8b018da5-e765-43f1-ad92-c776193a43cf"},"source":["# Prdiction on unlabeled data\r\n","\r\n","!nohup python3 model_transfer_v3.py --stage='predict_small' --base_path='./' --image_path='./images' \\\r\n","        --intermediate_vector_path='./test_big_model_vectors' --model_name='fashion_big_model_best' --input_vector_size=512 \\\r\n","        --intermediate_vector_size=128 --root_df='df_final.csv' --test_df='test.csv' --base_df='df_final_with_original_class.csv' \\\r\n","        --batch_size=32 --pred_df='test_pred.csv' &"],"execution_count":null,"outputs":[{"output_type":"stream","text":["nohup: appending output to 'nohup.out'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mSbqMcFDSH0N","executionInfo":{"status":"ok","timestamp":1612932747111,"user_tz":-330,"elapsed":1060,"user":{"displayName":"Subhan De","photoUrl":"","userId":"08832275770808375489"}},"outputId":"62a5b051-e405-49b6-8733-a1f2fbf7e83d"},"source":["!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["big_model_vectors\t\t  images.csv\t\ttest_big_model_vectors\n","DeepSpeedExamples\t\t  model_best.pt\t\ttest.csv\n","deepspeed_train_small.ipynb\t  model_deepspeed.py\ttest_final_vectors\n","df_final.csv\t\t\t  models\t\ttest_images\n","df_final_pred.csv\t\t  model_transfer_v3.py\ttest_images.zip\n","df_final_with_original_class.csv  nohup2.out\t\ttest_pred.csv\n","ds_config.json\t\t\t  nohup.out\t\ttrain.csv\n","efficientnet_vectors\t\t  __pycache__\t\ttrainer_deepspeed.py\n","final_vectors\t\t\t  styles.csv\t\ttrainer.ipynb\n","images\t\t\t\t  styles_df.csv\t\tval.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1HEgB-TaRStn","executionInfo":{"status":"ok","timestamp":1612936790597,"user_tz":-330,"elapsed":276494,"user":{"displayName":"Subhan De","photoUrl":"","userId":"08832275770808375489"}},"outputId":"38e0a5f8-a762-43b2-a471-2e2f9e1d5470"},"source":["# Prdiction on unlabeled data || deepspedd model\r\n","!python model_transfer_v3.py --stage='predict_small' --base_path='./' --image_path='./test_images' \\\r\n","        --intermediate_vector_path='./test_big_model_vectors' --model_name='fashion_deepspeed_best' --input_vector_size=512 \\\r\n","        --intermediate_vector_size=128 --root_df='df_final.csv' --test_df='test.csv' --base_df='df_final_with_original_class.csv' \\\r\n","        --batch_size=32 --pred_df='test_pred.csv'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["predict_small\n","Total Number of Images:  4633\n","Starting Extract Vector from Small model -------------------------\n","100% 145/145 [04:29<00:00,  1.86s/it]\n","(4633, 8)\n","Prediction file saved to  test_pred.csv\n","Stage: predict_small Finished ------------------------------------------------\n"],"name":"stdout"}]}]}